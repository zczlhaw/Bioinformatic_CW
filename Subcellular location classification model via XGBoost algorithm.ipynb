{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subcellular location classification model via XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingpae/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lingpae/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import ProtParam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, Preprocessing and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "def read_fasta(filenames):\n",
    "    target = filenames.split('.')[0]\n",
    "    seq_id = []\n",
    "    seq = []\n",
    "    len_seq = []\n",
    "    mole_weight = []\n",
    "    aromatic = []\n",
    "    inst_idx = []\n",
    "    hydro = []\n",
    "    iso_elec = []\n",
    "    sec_str_frac_1 = []\n",
    "    sec_str_frac_2 = []\n",
    "    sec_str_frac_3 = []\n",
    "    nls_f = []\n",
    "    \n",
    "    f_seq = []\n",
    "    f_mole_weight = []\n",
    "    f_aromatic = []\n",
    "    f_inst_idx = []\n",
    "    f_hydro = []\n",
    "    f_iso_elec = []\n",
    "    f_sec_str_frac_1 = []\n",
    "    f_sec_str_frac_2 = []\n",
    "    f_sec_str_frac_3 = []\n",
    "    \n",
    "    l_seq = []\n",
    "    l_mole_weight = []\n",
    "    l_aromatic = []\n",
    "    l_inst_idx = []\n",
    "    l_hydro = []\n",
    "    l_iso_elec = []\n",
    "    l_sec_str_frac_1 = []\n",
    "    l_sec_str_frac_2 = []\n",
    "    l_sec_str_frac_3 = []\n",
    "    \n",
    "    for seq_record in SeqIO.parse(filenames, \"fasta\"):\n",
    "        seq_id.append(seq_record.id)\n",
    "        \n",
    "        prep_seq = str(seq_record.seq)\n",
    "        prep_seq = prep_seq.replace(\"X\", \"\")\n",
    "        prep_seq = prep_seq.replace(\"U\", \"C\")\n",
    "        prep_seq = prep_seq.replace(\"B\", \"N\")\n",
    "        prep_seq = prep_seq.replace('Z', 'Q')\n",
    "        \n",
    "        seq.append(prep_seq)\n",
    "        len_seq.append(len(seq_record))\n",
    "        temp = ProtParam.ProteinAnalysis(prep_seq) \n",
    "        \n",
    "        mole_weight.append(temp.molecular_weight())\n",
    "        aromatic.append(temp.aromaticity())\n",
    "        inst_idx.append(temp.instability_index())\n",
    "        hydro.append(temp.gravy())\n",
    "        iso_elec.append(temp.isoelectric_point())\n",
    "        sec_str_frac_1.append(temp.secondary_structure_fraction()[0])\n",
    "        sec_str_frac_2.append(temp.secondary_structure_fraction()[1])\n",
    "        sec_str_frac_3.append(temp.secondary_structure_fraction()[2])\n",
    "        nls_f.append(nls_flag(prep_seq))\n",
    "        \n",
    "        temp_f_seq = prep_seq[0:50]\n",
    "        f_seq.append(temp_f_seq)\n",
    "        temp = ProtParam.ProteinAnalysis(temp_f_seq)\n",
    "\n",
    "        f_mole_weight.append(temp.molecular_weight())\n",
    "        f_aromatic.append(temp.aromaticity())\n",
    "        f_inst_idx.append(temp.instability_index())\n",
    "        f_hydro.append(temp.gravy())\n",
    "        f_iso_elec.append(temp.isoelectric_point())\n",
    "        f_sec_str_frac_1.append(temp.secondary_structure_fraction()[0])\n",
    "        f_sec_str_frac_2.append(temp.secondary_structure_fraction()[1])\n",
    "        f_sec_str_frac_3.append(temp.secondary_structure_fraction()[2])\n",
    "        \n",
    "        temp_l_seq = prep_seq[-50:]\n",
    "        l_seq.append(temp_l_seq)\n",
    "        temp = ProtParam.ProteinAnalysis(temp_l_seq)\n",
    " \n",
    "        l_mole_weight.append(temp.molecular_weight())\n",
    "        l_aromatic.append(temp.aromaticity())\n",
    "        l_inst_idx.append(temp.instability_index())\n",
    "        l_hydro.append(temp.gravy())\n",
    "        l_iso_elec.append(temp.isoelectric_point())\n",
    "        l_sec_str_frac_1.append(temp.secondary_structure_fraction()[0])\n",
    "        l_sec_str_frac_2.append(temp.secondary_structure_fraction()[1])\n",
    "        l_sec_str_frac_3.append(temp.secondary_structure_fraction()[2])\n",
    "\n",
    "    df = pd.DataFrame({ 'seq' : seq, 'len_seq' : len_seq, \n",
    "                       'mole_weight' : mole_weight,\n",
    "                       'aromatic' : aromatic, 'inst_idx' : inst_idx, 'hydro' : hydro,\n",
    "                       'iso_elec' : iso_elec,\n",
    "                       'sec_str_frac_1' : sec_str_frac_1, 'sec_str_frac_2' : sec_str_frac_2,\n",
    "                       'sec_str_frac_3' : sec_str_frac_3, 'nls_f' : nls_f,\n",
    "                       \n",
    "                       'f_seq' : f_seq, 'f_mole_weight' : f_mole_weight,\n",
    "                       'f_aromatic' : f_aromatic, 'f_inst_idx' : f_inst_idx, 'f_hydro' : f_hydro,\n",
    "                       'f_iso_elec' : f_iso_elec,\n",
    "                       'f_sec_str_frac_1' : f_sec_str_frac_1, 'f_sec_str_frac_2' : f_sec_str_frac_2,\n",
    "                       'f_sec_str_frac_3' : f_sec_str_frac_3,\n",
    "                       \n",
    "                       'l_seq' : l_seq, 'l_mole_weight' : l_mole_weight,\n",
    "                       'l_aromatic' : l_aromatic, 'l_inst_idx' : l_inst_idx, 'l_hydro' : l_hydro,\n",
    "                       'l_iso_elec' : l_iso_elec,\n",
    "                       'l_sec_str_frac_1' : l_sec_str_frac_1, 'l_sec_str_frac_2' : l_sec_str_frac_2,\n",
    "                       'l_sec_str_frac_3' : l_sec_str_frac_3\n",
    "                      },index = seq_id)\n",
    "    df['y'] = target\n",
    "    return df\n",
    "\n",
    "def data_pipeline(dat):\n",
    "    for a in amino_dic:\n",
    "        dat['num_' + a] = dat['seq'].str.count(a)\n",
    "        dat['p_' + a] = dat['seq'].str.count(a)/dat['len_seq']\n",
    "        dat['f_num_' + a] = dat['f_seq'].str.count(a)\n",
    "        dat['f_p_' + a] = dat['f_seq'].str.count(a)/50\n",
    "        dat['l_num_' + a] = dat['l_seq'].str.count(a)\n",
    "        dat['l_p_' + a] = dat['l_seq'].str.count(a)/50\n",
    "    for di in di_dic:\n",
    "        dat['num_' + di] = dat['seq'].str.count(di)\n",
    "        dat['f_num_' + di] = dat['f_seq'].str.count(di)\n",
    "        dat['l_num_' + di] = dat['f_seq'].str.count(di)\n",
    "    X = dat\n",
    "    X = X.drop(['y','seq', 'f_seq', 'l_seq'], axis = 1)\n",
    "    Y = dat['y']\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nls_db = pd.read_csv('nuclear.csv')\n",
    "nls_sig_list = nls_db['Sequence']\n",
    "\n",
    "cyto = read_fasta('cyto.fasta')\n",
    "mito = read_fasta('mito.fasta')\n",
    "nucleus = read_fasta('nucleus.fasta')\n",
    "secreted = read_fasta('secreted.fasta')\n",
    "\n",
    "df = pd.concat([cyto, mito, nucleus, secreted])\n",
    "\n",
    "amino_dic = ['I','L','V','F','M','C','A','G','P','T','S','Y','W','Q','N','H','E','D','K','R']\n",
    "di_dic = ['II','IL','IV','IF','IM','IC','IA','IG','IP','IT','IS','IY','IW','IQ','IN','IH','IE','ID','IK','IR',\n",
    "          'LI','LL','LV','LF','LM','LC','LA','LG','LP','LT','LS','LY','LW','LQ','LN','LH','LE','LD','LK','LR',\n",
    "          'VI','VL','VV','VF','VM','VC','VA','VG','VP','VT','VS','VY','VW','VQ','VN','VH','VE','VD','VK','VR',\n",
    "          'FI','FL','FV','FF','FM','FC','FA','FG','FP','FT','FS','FY','FW','FQ','FN','FH','FE','FD','FK','FR',\n",
    "          'MI','ML','MV','MF','MM','MC','MA','MG','MP','MT','MS','MY','MW','MQ','MN','MH','ME','MD','MK','MR',\n",
    "          'CI','CL','CV','CF','CM','CC','CA','CG','CP','CT','CS','CY','CW','CQ','CN','CH','CE','CD','CK','CR',\n",
    "          'AI','AL','AV','AF','AM','AC','AA','AG','AP','AT','AS','AY','AW','AQ','AN','AH','AE','AD','AK','AR',\n",
    "          'GI','GL','GV','GF','GM','GC','GA','GG','GP','GT','GS','GY','GW','GQ','GN','GH','GE','GD','GK','GR',\n",
    "          'PI','PL','PV','PF','PM','PC','PA','PG','PP','PT','PS','PY','PW','PQ','PN','PH','PE','PD','PK','PR',\n",
    "          'TI','TL','TV','TF','TM','TC','TA','TG','TP','TT','TS','TY','TW','TQ','TN','TH','TE','TD','TK','TR',\n",
    "          'SI','SL','SV','SF','SM','SC','SA','SG','SP','ST','SS','SY','SW','SQ','SN','SH','SE','SD','SK','SR',\n",
    "          'YI','YL','YV','YF','YM','YC','YA','YG','YP','YT','YS','YY','YW','YQ','YN','YH','YE','YD','YK','YR',\n",
    "          'WI','WL','WV','WF','WM','WC','WA','WG','WP','WT','WS','WY','WW','WQ','WN','WH','WE','WD','WK','WR',\n",
    "          'QI','QL','QV','QF','QM','QC','QA','QG','QP','QT','QS','QY','QW','QQ','QN','QH','QE','QD','QK','QR',\n",
    "          'NI','NL','NV','NF','NM','NC','NA','NG','NP','NT','NS','NY','NW','NQ','NN','NH','NE','ND','NK','NR',\n",
    "          'HI','HL','HV','HF','HM','HC','HA','HG','HP','HT','HS','HY','HW','HQ','HN','HH','HE','HD','HK','HR',\n",
    "          'EI','EL','EV','EF','EM','EC','EA','EG','EP','ET','ES','EY','EW','EQ','EN','EH','EE','ED','EK','ER',\n",
    "          'DI','DL','DV','DF','DM','DC','DA','DG','DP','DT','DS','DY','DW','DQ','DN','DH','DE','DD','DK','DR',\n",
    "          'KI','KL','KV','KF','KM','KC','KA','KG','KP','KT','KS','KY','KW','KQ','KN','KH','KE','KD','KK','KR',\n",
    "          'RI','RL','RV','RF','RM','RC','RA','RG','RP','RT','RS','RY','RW','RQ','RN','RH','RE','RD','RK','RR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data_pipeline(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Search Cross validation\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "        'silent': [False],\n",
    "        'max_depth': [5, 7, 10, 11, 12, 13, 14, 15],\n",
    "        'learning_rate': [0.001,0.01, 0.05, 0.1],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0, 13.0],\n",
    "        'gamma': [0,0.1,0.2, 0.25, 0.5],\n",
    "        'n_estimators': [70, 100,400, 500, 1000],\n",
    "        'objective' : 'multi:softmax'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_A = {'eval_metric': 'mlogloss',\n",
    "              'early_stopping_rounds': 10,\n",
    "              'eval_set': [(X_val, y_val)]}\n",
    "clf = RandomizedSearchCV(clf, param_grid, n_iter=20,\n",
    "                            n_jobs=5, verbose=2, cv=5,\n",
    "                            fit_params=fit_params_A,\n",
    "                            random_state=42)\n",
    "#                             scoring='roc_auc')\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = model_A.best_score_\n",
    "best_params = model_A.best_params_\n",
    "print(\"Best score: {}\".format(best_score))\n",
    "print(\"Best params: \")\n",
    "for param_name in sorted(best_params.keys()):\n",
    "    print('%s: %r' % (param_name, best_params[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Model\n",
    "clf = xgb.XGBClassifier(colsample_bylevel =  0.9,\n",
    "                        colsample_bytree= 0.6,\n",
    "                        gamma= 0.5,\n",
    "                        learning_rate= 0.1,\n",
    "                        max_depth= 13,\n",
    "                        min_child_weight= 10.0,\n",
    "                        n_estimators= 500,\n",
    "                        objective = 'multi:softmax',\n",
    "                        silent= False,\n",
    "                        subsample= 0.7,\n",
    "                        random_state=42)\n",
    "clf.fit(X_train, y_train,eval_metric = 'mlogloss',\n",
    "              early_stopping_rounds = 10,\n",
    "              eval_set = [(X_val, y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of XGBoost classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = ['cyto', 'mito', 'nucleus', 'secreted']\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred,  \n",
    "             target_names= ['cyto','mito','nucleus','secreted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "trail = pd.DataFrame(clf.feature_importances_,X_train.columns.values)\n",
    "trail.sort_values(by=0, ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind = read_fasta('blind.fasta')\n",
    "blind_X, _ = data_pipeline(blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'predict' : clf.predict(blind_X),\n",
    "              'Confident' : np.max(clf.predict_proba(blind_X), axis = 1)\n",
    "             },index=blind_X.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
